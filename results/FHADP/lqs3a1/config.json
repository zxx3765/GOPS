{
    "env_id": "pyth_lq",
    "lq_config": "s3a1",
    "algorithm": "FHADP",
    "pre_horizon": 80,
    "enable_cuda": false,
    "reward_scale": 1,
    "reward_shift": 0,
    "obs_scale": [
        1,
        2,
        0.5
    ],
    "obs_shift": [
        1,
        1,
        1
    ],
    "action_type": "continu",
    "is_render": false,
    "is_adversary": false,
    "value_func_type": "MLP",
    "policy_func_name": "FiniteHorizonPolicy",
    "policy_func_type": "MLP",
    "policy_act_distribution": "default",
    "policy_hidden_sizes": [
        64,
        64
    ],
    "policy_hidden_activation": "elu",
    "policy_output_activation": "linear",
    "policy_learning_rate": 0.0003,
    "trainer": "off_serial_trainer",
    "max_iteration": 6000,
    "ini_network_dir": null,
    "buffer_name": "replay_buffer",
    "buffer_warm_size": 1000,
    "buffer_max_size": 100000,
    "replay_batch_size": 64,
    "sample_interval": 1,
    "sampler_name": "off_sampler",
    "sample_batch_size": 1,
    "noise_params": {
        "mean": [
            0.0
        ],
        "std": [
            0.20000000298023224
        ]
    },
    "evaluator_name": "evaluator",
    "num_eval_episode": 10,
    "eval_interval": 100,
    "eval_save": false,
    "save_folder": "D:\\Projects\\G_GOPS\\GOPS\\GOPS_20221209/results/FHADP\\221209-212335",
    "apprfunc_save_interval": 500,
    "log_save_interval": 200,
    "use_gpu": false,
    "batch_size_per_sampler": 1,
    "obsv_dim": 3,
    "action_dim": 1,
    "action_high_limit": [
        5.0
    ],
    "action_low_limit": [
        -5.0
    ],
    "additional_info": {},
    "cnn_shared": false,
    "seed": 4028392146
}