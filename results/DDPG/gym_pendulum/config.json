{
    "env_id": "gym_pendulum",
    "algorithm": "DDPG",
    "enable_cuda": false,
    "action_type": "continu",
    "is_render": false,
    "is_adversary": false,
    "value_func_name": "ActionValue",
    "value_func_type": "MLP",
    "value_hidden_sizes": [
        64,
        64
    ],
    "value_hidden_activation": "relu",
    "value_output_activation": "linear",
    "policy_func_name": "DetermPolicy",
    "policy_func_type": "MLP",
    "policy_act_distribution": "default",
    "policy_hidden_sizes": [
        64,
        64
    ],
    "policy_hidden_activation": "relu",
    "policy_output_activation": "linear",
    "value_learning_rate": 0.001,
    "policy_learning_rate": 0.001,
    "trainer": "off_serial_trainer",
    "max_iteration": 8000,
    "ini_network_dir": null,
    "buffer_name": "replay_buffer",
    "buffer_warm_size": 1000,
    "buffer_max_size": 100000,
    "replay_batch_size": 64,
    "sample_interval": 1,
    "sampler_name": "off_sampler",
    "sample_batch_size": 8,
    "noise_params": {
        "mean": [
            0.0
        ],
        "std": [
            0.20000000298023224
        ]
    },
    "evaluator_name": "evaluator",
    "num_eval_episode": 10,
    "eval_interval": 100,
    "eval_save": false,
    "save_folder": "D:\\wwx\\PHD\\Project\\GOPS\\GOPS_code\\temp/results/DDPG\\221209-133922",
    "apprfunc_save_interval": 5000,
    "log_save_interval": 100,
    "use_gpu": false,
    "batch_size_per_sampler": 8,
    "obsv_dim": 3,
    "action_dim": 1,
    "action_high_limit": [
        2.0
    ],
    "action_low_limit": [
        -2.0
    ],
    "additional_info": {},
    "cnn_shared": false,
    "seed": 2199111670
}